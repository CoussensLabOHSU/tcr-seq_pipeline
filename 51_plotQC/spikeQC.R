#!/usr/bin/Rscript

###################
### DESCRIPTION ###~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
###################

### Read in the QC files generated by the 9-bp and 25-bp spike count processes.
### Each directory contains files of the format batch_S[0-9]+.assembled.qc.txt
### Aggregate them into summary tables:
  ### 9-bp table - 1 row per sample, columns:
    ### Number of Reads
    ### Number of Spiked Reads
    ### Percent of Spiked Reads
  ### 25-bp table - 1 row per sample, columns:
    ### Number of Reads
    ### Number of Spiked Reads
    ### Percent of Spiked Reads
    ### 1 column per spike, containing number of reads.
  ### Overall Summary table - 5 columns for 'fivenum' values, rows:
    ### Number of Reads
    ### Number of Spiked Reads
    ### Percent of Spiked Reads
    ### 1 row per spike
    ### Uses 25-bp data, unless not provided, then uses 9-bp
###
### Generate a few QC plots:
  ### Percentage of total spikes in each sample (using 9bp) - box/violin plot
  ### Percentage of individual spikes in each sample (using 25bp) - box/violin plot
###
### If a metadata file is provided, split the violins by color and/or facet.
### Color generally corresponds to treatment, while facet corresponds to tissue, but can change.

####################
### DEPENDENCIES ###~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
####################
### Load dependencies
#.libPaths("/home/exacloud/gscratch/CoussensLab/howellsf/R-4.0.2/library")

suppressMessages(library(ggplot2))
suppressMessages(library(data.table))
suppressMessages(library(optparse))
suppressMessages(library(wrh.rUtils))
options("scipen" = 100)

####################
### COMMAND LINE ###~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
####################

### Make command line
optlist <- list(
  make_option(
    c("-n", "--nine"),
    type = "character",
    help = "Path to directory of 9-bp spike count QC files. Will only read files with format ^[A-Z][0-9][LC]_S[0-9]+\\.[a-z\\._]*$"
  ),
  make_option(
    c("-t", "--twentyFive"),
    type = "character",
    help = "Path to directory of 25-bp spike count QC files. Will only read files with format ^[A-Z][0-9][LC]_S[0-9]+\\.[a-z\\._]*$"
  ),
  make_option(
    c("-o", "--outDir"),
    type = "character",
    help = "Path to directory to write output files. If this argument is not used, will write to inputDir."
  ),
  make_option(
    c("-m", "--metaFile"),
    type = "character",
    help = "(Optional) path to metadata file. Used to divide plots by treatment, if provided."
  ),
  make_option(
    c("-c", "--colorCol"),
    type = "character",
    help = "(Optional) metadata column name used to separate samples using different colors. Only used if metaFile is provided.
    Default is 'Treatment'. Provide 'NA' to skip."
  ),
  make_option(
    c("-f", "--facetCol"),
    type = "character",
    help = "(Optional) metadata column used to separate samples by facets. Only used if metaFile is provided.
    Default is 'Tissue'. Provide 'NA' to skip."
  )
)

### Parse command line
p <- OptionParser(usage = "%prog -n nine -t twentyFive -o outDir -m metaFile -c colorCol -f facetCol",
                  option_list = optlist)
args <- parse_args(p)
opt <- args$options

### Get arguments
nineDir_v <- args$nine
twentyFiveDir_v <- args$twentyFive
outDir_v <- args$outDir
metaFile_v <- args$metaFile
colorCol_v <- args$colorCol
facetCol_v <- args$facetCol

### For testing
#nineDir_v <- "~/OHSU/tcr_spike/data/test_collab/spike_counts/9bp/qc/"
#twentyFiveDir_v <- "~/OHSU/tcr_spike/data/test_collab/spike_counts/25bp/qc/"
#outDir_v <- "~/OHSU/tcr_spike/data/test_collab/out/"
#metaFile_v <- "~/OHSU/tcr_spike/data/test_collab/meta.txt"
#colorCol_v <- "Treatment"
#facetCol_v <- "Source"

###################
### HANDLE NULL ###~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
###################

### outDir_v becomes inputDir_v, if NULL
if (is.null(outDir_v)) outDir_v <- inputDir_v

### Message regarding included directories
if (is.null(nineDir_v)) message("No directory provided for nineDir. Will NOT run 9-bp portion of QC.")
if (is.null(twentyFiveDir_v)) message("No directory provided for nineDir. Will NOT run 25-bp portion of QC.")

### Lots of metadata stuff to do if it's provided. Do nothing otherwise
if (!is.null(metaFile_v)) {
  
  ## Read data
  meta_dt <- fread(metaFile_v)
  
  ## Get sample column
  sampleCol_v <- grep("[Ss]ample", colnames(meta_dt), value = T)
  if (length(sampleCol_v) == 0) {
    stop("metaFile provided, but couldn't find 'Sample' column.\n",
         sprintf("Current columns are: %s\n", paste(colnames(meta_dt), collapse = " - ")),
         "Please rename the column with sample numbers to 'Sample'.")
  } # fi
  
  ## Get color-separating column
  colorCol_v <- ifelse(is.null(colorCol_v), grep("[Tt]reatment|[Tt]reat", colnames(meta_dt), value = T), colorCol_v)
  if (is.na(colorCol_v)) {
    colorCol_v <- NULL
    warning("metaFile provided, but color column was NULL and no corresponding column was found.\n",
            sprintf("Current columns are: %s\n", paste(colnames(meta_dt), collapse = " - ")),
            "This is only a problem if you would like to split plots by a particular variable.\n")
  } else {
    cat(sprintf("Will split samples by color using: %s\n", colorCol_v))
  } # fi
  
  ## Get faceting column
  facetCol_v <- ifelse(is.null(facetCol_v), grep("[Tt]issue", colnames(meta_dt), value = T), facetCol_v)
  if (is.na(facetCol_v)) {
    facetCol_v <- NULL
    message("metaFile provided, but facet column was NULL and no corresponding column was found.\n",
            sprintf("Current columns are: %s\n", paste(colnames(meta_dt), collapse = " - ")),
            "This is only a problem if you would like to facet plots by a particular variable.\n")
  } else {
    cat(sprintf("Will facet plots by: %s\n", facetCol_v))
  } # fi
  
  ## Add 'S' to front of samples
  meta_dt[[sampleCol_v]] <- paste0("S", gsub("^S", "", meta_dt[[sampleCol_v]]))
  
} # fi

#############
### SETUP ###~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
#############

### Combine into list
dirs_lsv <- list("nine" = nineDir_v, "twentyFive" = twentyFiveDir_v)

### Get files, add names, and sort them
files_lsv <- lapply(dirs_lsv, function(x) { 
  if (!is.null(x)) {
    files_v <- list.files(x, pattern = "^[A-Z]+[0-9]+LC_S[0-9]+\\.[a-z\\._]*$")
    names(files_v) <- paste0("S", gsub("^.*_S|\\..*$", "", files_v))
    files_v <- files_v[order(as.numeric(gsub("S", "", names(files_v))))]
    } # fi
  })

### Make output data.frames
cols_v <- c("num.reads", "num.spiked.reads", "pct.spiked.reads")
out_lsdf <- lapply(files_lsv, function(x) {
  if (!is.null(x)) {
    df <- data.frame("Sample" = names(x), stringsAsFactors = F)
    for (col_v in cols_v) df[[col_v]] <- numeric(length(x))
    return(df)
  } # fi
})

### Make summary data.frame and add columns to twentyFive data.frame, if required.
if (is.null(twentyFiveDir_v)) {
  out_lsdf[["overallSummary"]] <- as.data.frame(matrix(nrow = 3, ncol = 6))
} else {
  out_lsdf[["overallSummary"]] <- as.data.frame(matrix(nrow = 263, ncol = 6))
  out_lsdf$twentyFive <- cbind(out_lsdf$twentyFive, as.data.frame(matrix(nrow = nrow(out_lsdf$twentyFive), ncol = 260)))
} # fi

### Make output names
textOut_lsv <- as.list(file.path(outDir_v, paste0(names(out_lsdf), "Counts.txt")))
names(textOut_lsv) <- names(out_lsdf)

plotNames_lsv <- list()
for (i in 1:length(files_lsv)) {

  ## Get name
  currName_v <- names(files_lsv)[i]

  ## Make file
  if (currName_v == "nine") {
    plotNames_lsv[[currName_v]] <- file.path(outDir_v, paste0(currName_v, "_pctSpike.pdf"))
  } else if (currName_v == "twentyFive") {
    names_v <- c("_pctSpike.pdf", "_pctSpikeLog10.pdf", "_spikesBySample.pdf",
                 "_spikesBySampleLog10.pdf", "_spikesByNumReadsPct.pdf", "_spikesByNumReadsCount.pdf")
    outNames_v <- paste0(currName_v, names_v)
    plotNames_lsv[[currName_v]] <- file.path(outDir_v, outNames_v)
  } # fi
} # for

############
### READ ###~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
############

for (i in 1:length(files_lsv)) {
  
  ## Get name, directory, files, and output directory
  currName_v <- names(files_lsv)[i]
  currDir_v <- dirs_lsv[[currName_v]]
  currFiles_v <- files_lsv[[currName_v]]
  currOut_df <- out_lsdf[[currName_v]]
  currOutName_v <- textOut_lsv[[currName_v]]
  
  ## Read through and summarize
  if (!is.null(currFiles_v)) {
    for (j in 1:length(currFiles_v)) {
      
      ## Get sample and data
      currSample_v <- names(currFiles_v)[j]
      currData_dt <- fread(file.path(currDir_v, currFiles_v[j]))
      
      ## Get batch name
      batch_v <- unname(gsub("_S[0-9]+.*$", "", currFiles_v[j]))
      
      ## Add info to output
      currOut_df[j,cols_v] <- currData_dt[1,mget(cols_v)]
      
      ## If twentyFiveDir, need to add all
      if (currName_v == "twentyFive") {
        spikeCols_v <- grep("DM_*", colnames(currData_dt), value = T)
        if (j == 1) {colnames(currOut_df) <- c("Sample", cols_v, spikeCols_v)}
        currOut_df[j,spikeCols_v] <- currData_dt[1,mget(spikeCols_v)]
      } # fi
    } # for j
  } # fi
  
  ## Add back to list
  out_lsdf[[currName_v]] <- currOut_df
  
  ## Write
  if (!is.null(currOut_df)) {
    write.table(currOut_df, file = currOutName_v, sep = '\t', quote = F, row.names = F)
  } # fi
  
} # for i

###############
### SUMMARY ###~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
###############

### Get data to use for summary
which_v <- ifelse(is.null(twentyFiveDir_v), "nine", "twentyFive")
toSummarize_df <- out_lsdf[[which_v]]
toSummarizeCols_v <- grep("Sample", colnames(toSummarize_df), value = T, invert = T)

### Change column names
fiveNumCols_v <- c( "Min", "lowerQ", "Median", "upperQ", "Max")
colnames(out_lsdf$overallSummary) <- c("Category", fiveNumCols_v)
out_lsdf$overallSummary$Category <- toSummarizeCols_v

### Change column classes
for (col_v in fiveNumCols_v) out_lsdf$overallSummary[[col_v]] <- as.integer(out_lsdf$overallSummary[[col_v]])

### Summarize
for (i in 1:length(toSummarizeCols_v)) {
  ## Get column and data
  currCol_v <- toSummarizeCols_v[i]
  currData_v <- as.integer(fivenum(toSummarize_df[,currCol_v]))
  ## Add
  out_lsdf$overallSummary[i,fiveNumCols_v] <- currData_v
}

### Write
write.table(out_lsdf$overallSummary, textOut_lsv[["overallSummary"]], sep = '\t', quote = F, row.names = F)

############
### PLOT ###~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
############

if (is.null(metaFile_v)) {
  
  ###
  ### 9-bp Plot ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  ###
  
  if (!is.null(nineDir_v)) {
    
    ## Melt
    melt_df <- melt(as.data.table(out_lsdf$nine), id.vars = "Sample")
    
    ## Subset
    plot_df <- melt_df[melt_df$variable == "pct.spiked.reads",]
    
    ## Plot
    nine_gg <- ggplot(data = plot_df, aes(x = variable, y = value)) +
      geom_violin(trim = F) +
      stat_summary(fun.y = median, geom = "point", size = 2) +
      ylab("Percent") +
      ggtitle(paste(batch_v, "Percent Spiked Reads")) +
      theme_classic() +
      theme(plot.title = element_text(hjust = 0.5, size = 20),
            axis.text.x = element_blank(),
            axis.title.x = element_blank(),
            axis.ticks.x = element_blank(),
            axis.text.y = element_text(size = 16),
            axis.title.y = element_text(size = 18))
    
    ## Write
    pdf(file = plotNames_lsv$nine)
    print(nine_gg)
    dev.off()
    
    ## Check > 50%
    ranges_lsv <- list(c(50, 60), c(60, 70), c(70, 80), c(80,90), c(90,100))
    nineOut_df <- as.data.frame(matrix(nrow = length(ranges_lsv), ncol = 2))
    for (i in 1:length(ranges_lsv)) {
      samples_v <- plot_df[plot_df$value > ranges_lsv[[i]][1] &
                             plot_df$value <= ranges_lsv[[i]][2], "Sample"]
      nineOut_df[i,] <- c(paste(ranges_lsv[[i]][1], ranges_lsv[[i]][2], sep = "_"),
                          paste(samples_v, collapse = "; "))
    }
    colnames(nineOut_df) <- c("Spike Percentage", "Samples")
    
    ## Write
    write.table(nineOut_df, file = file.path(outDir_v, "highSpikePct.txt"), sep = "\t", quote = F, row.names = F)
    
  } # fi
  
  ###
  ### 25-bp Plot ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  ###
  
  if (!is.null(twentyFiveDir_v)) {
    
    ##
    ## CHECK COUNTS ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    ##

    ## Get data
    tf_df <- out_lsdf$twentyFive

    ## Get zero pct
    tf_0pct_df <- tf_df[tf_df$pct.spiked.reads == 0,]
    tf_0count_df <- tf_df[tf_df$num.spiked.reads == 0,]

    ## Extract summary
    tfSummary_df <- tf_df[,c("Sample", "num.reads", "num.spiked.reads", "pct.spiked.reads")]

    ## Check results
    if ((nrow(tf_0pct_df) > 0 | nrow(tf_0count_df) > 0)) {

      ## Make sure rows are same
      if (nrow(tf_0count_df) != nrow(tf_0pct_df)) {
        warning(sprintf("Mismatch between number of 0-count (%s) and 0-pct (%s) rows.",
                        nrow(tf_0count_df), nrow(tf_0pct_df)))
      } # fi
      
      ## Make sure samples are the same
      pctUniq_v <- setdiff(tf_0pct_df$Sample, tf_0count_df$Sample)
      countUniq_v <- setdiff(tf_0count_df$Sample, tf_0pct_df$Sample)
      mismatchSamples_v <- union(pctUniq_v, countUniq_v)
      if (length(mismatchSamples_v) > 0) {
        warning(sprintf("Mismatch between 0-count and 0-pct samples.\n\t0-count uniq: %s\n\t0-pct uniq: %s\n",
                paste(countUniq_v, collapse = "; "), paste(pctUniq_v, collapse = "; ")))
      } else {
        badSamples_v <- tf_0pct_df$Sample
        warning(sprintf("Following samples have 0 spikes and will be removed: %s\n", paste(badSamples_v, collapse = "; ")))
        tf_df <- tf_df[!(tf_df$Sample %in% badSamples_v),]
      } # fi
    } # fi


    ##
    ## X-AXIS IS SPIKES, BOXES CONTAIN 1 POINT PER SAMPLE
    ##
    
    ## Convert to percentage
    tf_df[,spikeCols_v] <- tf_df[,spikeCols_v] / tf_df$num.spiked.reads * 100
    
    ## Get means
    colMeans_v <- colMeans(tf_df[,spikeCols_v], na.rm = T)
    rowMedians_v <- apply(tf_df[,spikeCols_v], 1, function(x) median(x, na.rm = T))
    nonZeroRowMedians_v <- apply(tf_df[,spikeCols_v], 1, function(x) median(x[which(x != 0)], na.rm = T))
    names(rowMedians_v) <- tf_df$Sample
    names(nonZeroRowMedians_v) <- tf_df$Sample
    
    ## Remove summary cols and sort
    tf_df <- tf_df[,c("Sample", spikeCols_v[order(colMeans_v)])]
    
    ## Melt
    melt_df <- melt(as.data.table(tf_df), id.vars = "Sample")
    
    ## Log transform
    melt_df$log10 <- log10(melt_df$value + 1)
    #melt_df[is.infinite(melt_df$log10), "log10"] <- 0
    
    ## Calculate medians
    temp <- melt_df; temp[1,1] <- temp[1,1]
    temp[,med := median(value), by = variable]
    temp <- unique(temp[,mget(c("variable", "med"))])
    
    ## Which are greater than 0.366
    tooLarge_v <- temp[med > 0.385,variable]
    cat(sprintf("%d spikes with greater median values\n than 0.385\n", length(tooLarge_v)))
    
    ## Plot
    tf_gg1 <- ggplot(data = melt_df, aes(x = variable, y = value)) +
      geom_boxplot() +
      geom_hline(yintercept = 0.385) +
      labs(x = "Spike", y = "Percent") +
      scale_y_log10(breaks = c(0.01, 0.385, 1, 10, 50, 100)) +
      ggtitle(paste(batch_v, "Percent Of All Spiked Reads")) +
      big_label() +
      theme(axis.text.x = element_blank(),
            axis.ticks.x = element_blank())
      
      tf_gg2 <- ggplot(data = melt_df, aes(x = variable, y = log10)) +
        geom_boxplot() +
        labs(x = "Spike", y = "log10(Percent)") +
        ggtitle(paste(batch_v, "Percent Of All Spiked Reads")) +
        big_label() + 
      theme(axis.text.x = element_blank(),
            axis.ticks.x = element_blank())
            
    
    ## Write
    pdf(file = plotNames_lsv$twentyFive[1])
    print(tf_gg1)
    dev.off()
    
    pdf(file = plotNames_lsv$twentyFive[2])
    print(tf_gg2)
    dev.off()
    
    ##
    ## X-AXIS IS SAMPLE, BOXES CONTAIN 1 POINT PER SPIKE
    ##
    
    ## Order
    #rowOrder_v <- sort(rowMedians_v, decreasing = T)
    rowOrder_v <- sort(nonZeroRowMedians_v)
    melt_df$Sample <- factor(melt_df$Sample, levels = names(rowOrder_v))
    
    tf_gg3 <- ggplot(data = melt_df, aes(x = Sample, y = value)) +
      geom_boxplot() +
      geom_hline(yintercept = 0.385) +
      labs(x = "Sample", y = "Percent") +
      scale_y_log10(breaks = c(0.01, 0.385, 1, 10, 50, 100)) +
      ggtitle(paste(batch_v, "Spike distrib. in each Sample")) +
      big_label() +
      theme(axis.text.x = element_blank(),
            axis.ticks.x = element_blank())
    
    tf_gg4 <- ggplot(data = melt_df, aes(x = Sample, y = log10)) +
      geom_boxplot() +
      labs(x = "Sample", y = "log10(Percent)") +
      ggtitle(paste(batch_v, "Spike distrib. in each Sample")) +
      big_label() +
      theme(axis.text.x = element_blank(),
            axis.ticks.x = element_blank())
    
    ## Write
    pdf(file = plotNames_lsv$twentyFive[3])
    print(tf_gg3)
    dev.off()
    
    pdf(file = plotNames_lsv$twentyFive[4])
    print(tf_gg4)
    dev.off()
    
    ##
    ## NUMBER OF SPIKES OUT OF 260
    ##
    
    ## Get number of spikes
    spikes_v <- grep("Sample", colnames(tf_df), value = T, invert = T)
    numSpikes_v <- apply(tf_df[,spikes_v], 1, function(x) length(which(unlist(x) != 0)))
    names(numSpikes_v) <- tf_df$Sample
    pctSpikes_v <- numSpikes_v / 260 * 100
    pctSpikes_df <- data.frame("Sample" = paste0("S", gsub("^S", "", names(pctSpikes_v))), "pctSpikes" = pctSpikes_v, "numSpikes" = numSpikes_v)
    tfSummary_df <- merge(tfSummary_df, pctSpikes_df, by = "Sample", sort = F)
    tfSummary_df <- as.data.table(tfSummary_df)
    
    ## Add label
    tfSummary_df$label <- ""
    tfSummary_df[numSpikes <= 230, label := Sample]
    
    ## Make plots
    tf_gg5 <- ggplot(tfSummary_df, aes(x = num.reads, y = pctSpikes)) +
      geom_point() +
      ggrepel::geom_text_repel(aes(label = label)) +
      labs(x = "Number of Reads", y = "Pct of Unique 260 Spikes") +
      ggtitle("Unique Spikes Found Based on Number of Reads") +
      big_label() +
      theme(panel.grid.major.y = element_line(color="grey60")) +
      scale_x_log10(breaks = c(100, 10000, 100000, 1000000)) +
      scale_y_continuous(breaks = seq(50,250,by=50))
    
    tf_gg6 <- ggplot(tfSummary_df, aes(x = num.reads, y = numSpikes)) +
      geom_point() +
      ggrepel::geom_text_repel(aes(label = label)) +
      labs(x = "Number of Reads", y = "Number Unique Spikes") +
      ggtitle("Unique Spikes Found Based on Number of Reads") +
      big_label() +
      theme(panel.grid.major = element_line(color="grey60")) +
      scale_x_log10(breaks = c(100, 10000, 100000, 1000000)) +
      scale_y_continuous(breaks = seq(50,250,by=50))
    
    ## Write
    pdf(file = plotNames_lsv$twentyFive[5])
    print(tf_gg5)
    dev.off()
    
    pdf(file = plotNames_lsv$twentyFive[6])
    print(tf_gg6)
    dev.off()

  } # fi
  
} else {
  
  ###
  ### 9-bp Plot ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  ###
  
  if (!is.null(nineDir_v)) {
    
    ## Merge
    metaCols_v <- c(colorCol_v, facetCol_v)
    merge_dt <- merge(meta_dt[,mget(c(sampleCol_v, metaCols_v))], out_lsdf$nine, by.x = sampleCol_v, by.y = "Sample", sort = F)
    
    ## Melt
    melt_dt <- melt(merge_dt, id.vars = c(sampleCol_v, metaCols_v))
    
    ## Subset
    plot_dt <- melt_dt[melt_dt$variable == "pct.spiked.reads",]
    
    ## Determine if violin or box plot
    ## Box plot if at least one grouping has only 2 observations
    sub_dt <- plot_dt[,mget(metaCols_v)]
    count_table <- table(sub_dt)
    minObs_v <- min(count_table)
    
    ## Base Plot
    nine_gg <- ggplot(data = plot_dt, aes(x = variable, y = value))
    
    ## Add box or violin
    if (minObs_v > 2) {
      nine_gg <- nine_gg + geom_violin()
    } else {
      nine_gg <- nine_gg + geom_boxplot()
    } # fi
    
    ## Split by color
    if (!is.null(colorCol_v)) {
      nine_gg <- nine_gg + aes_string(color = colorCol_v)
    }
    
    ## Facet
    if (!is.null(facetCol_v)) {
      nine_gg <- nine_gg + facet_wrap(as.formula(paste("~", facetCol_v)))
    }
    
    ## Add other info
    nine_gg <- nine_gg +
      ylab("Percent") +
      ggtitle(paste(batch_v, "Percent Spiked Reads"))
    
    ## Modify theme
    nine_gg <- nine_gg +
      theme_classic() +
      theme(plot.title = element_text(hjust = 0.5, size = 20),
            axis.text.x = element_blank(),
            axis.title.x = element_blank(),
            axis.ticks.x = element_blank(),
            axis.text.y = element_text(size = 16),
            axis.title.y = element_text(size = 18),
            strip.text = element_text(size = 18),
            legend.position = "bottom")
    
    ## Write
    pdf(file = plotNames_lsv$nine)
    print(nine_gg)
    dev.off()
  } # fi
  
  ###
  ### 25-bp Plot ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  ###
  
  if (!is.null(twentyFiveDir_v)) {
    
    ## Convert to percentage
    tf_df <- out_lsdf$twentyFive
    tf_df[,spikeCols_v] <- tf_df[,spikeCols_v] / tf_df$num.spiked.reads * 100
    
    ## Get means
    means_v <- colMeans(tf_df[,spikeCols_v], na.rm = T)
    
    ## Remove summary cols and sort
    tf_df <- tf_df[,c("Sample", spikeCols_v[order(means_v)])]
    
    ## Merge
    metaCols_v <- c(colorCol_v, facetCol_v)
    merge_dt <- merge(meta_dt[,mget(c(sampleCol_v, metaCols_v))], tf_df, by.x = sampleCol_v, by.y = "Sample", sort = F)
    
    ## Melt
    melt_dt <- melt(merge_dt, id.vars = c(sampleCol_v, metaCols_v))
    
    ## Iterate over 'colorCol', if specified
    if (is.null(colorCol_v)) {
      split_lsv <- list(unique(melt_dt[[colorCol_v]]))
    } else {
      split_lsv <- as.list(unique(melt_dt[[colorCol_v]]))
    } # fi
    
    for (i in 1:length(split_lsv)) {
      
      ## Handle color column
      currColorCol_v <- split_lsv[[i]]
      if (length(currColorCol_v) > 1) {
        outName_v <- plotNames_lsv$twentyFive
        title_v <- paste(batch_v, "Percent of All Spiked Reads")
      } else {
        outName_v <- paste0(gsub("_pctSpike.pdf", "", plotNames_lsv$twentyFive), currColorCol_v, "_pctSpike.pdf")
        title_v <- paste(batch_v, "Percent of All Spiked Reads\n", currColorCol_v)
      } # fi
      
      ## Subset data
      currPlot_dt <- melt_dt[get(colorCol_v) %in% currColorCol_v,]
      
      ## Make base plot
      tf_gg <- ggplot(data = currPlot_dt, aes(x = variable, y = value)) +
        geom_boxplot() +
        scale_y_log10()
      
      ## Facet
      if (!is.null(facetCol_v)) {
        tf_gg <- tf_gg + facet_wrap(as.formula(paste("~", facetCol_v)))
      }
      
      ## Add other info
      tf_gg <- tf_gg +
        ylab("Percent") +
        xlab("Spike") +
        ggtitle(title_v)
      
      ## Modify theme
      tf_gg <- tf_gg +
        theme_classic() +
        theme(plot.title = element_text(hjust = 0.5, size = 20),
              axis.text.x = element_blank(),
              axis.title.x = element_blank(),
              axis.ticks.x = element_blank(),
              axis.text.y = element_text(size = 16),
              axis.title.y = element_text(size = 18),
              strip.text = element_text(size = 18),
              legend.position = "bottom")
      
      ## Write
      pdf(file = outName_v)
      print(tf_gg)
      dev.off()
    } # for i

  } # fi
  
} # fi
